{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72819208-31d6-4cf9-908b-d890f7ffc428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded messages: 4098\n",
      "After removing very-short messages: 2649\n",
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9aa779bc3804bfbad127fb04090506a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([2649, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering: 100%|████████████████████████████████████████████████████████████████| 2649/2649 [00:00<00:00, 6462.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved message-level clusters -> D:\\Darryl\\Coding\\s_p\\data\\processed\\messages_with_clusters_v2.csv\n",
      "✅ Saved cluster summary -> D:\\Darryl\\Coding\\s_p\\data\\processed\\cluster_templates_v2.csv\n",
      "✅ Saved per-cluster examples -> D:\\Darryl\\Coding\\s_p\\data\\processed\\cluster_examples_v2\n",
      "\n",
      "Top clusters with high-risk dominance:\n",
      "      cluster_id  n_messages  \\\n",
      "0             -1        1053   \n",
      "1005        1529          20   \n",
      "315          441           7   \n",
      "452          646           2   \n",
      "336          493           5   \n",
      "596          971           1   \n",
      "593          968           1   \n",
      "592          967           1   \n",
      "590          965           1   \n",
      "736         1123           1   \n",
      "\n",
      "                                        example_message  \\\n",
      "0                      low risk setup spic 112 5 to 118   \n",
      "1005  जय श र श य म 𝗚𝗢𝗢𝗗 𝗠𝗢𝗥𝗡𝗜𝗡𝗚 𝗧𝗥𝗔𝗗𝗘𝗥𝗦 𝗨𝗡𝗠𝗨𝗧𝗘 𝗢𝗨𝗥 𝗖...   \n",
      "315                          #stocktowatch by cnbc tv18   \n",
      "452   join as a premium member for more sureshot tra...   \n",
      "336                              paid group trade check   \n",
      "596   book partial profit in buy 2 3 lot of m m @ 79...   \n",
      "593   book fantastic profit in short-sell 2 3 lot of...   \n",
      "592   on 29th jan 2021 booked fantastic profit in bu...   \n",
      "590   daily nifty level for nifty traders nifty supp...   \n",
      "736   1st jackpot call 50300 ce buy 413 to 500-510 h...   \n",
      "\n",
      "                                     canonical_template  high_msgs  med_msgs  \\\n",
      "0        low risk setup spic __num__ __num__ to __num__         71       149   \n",
      "1005  जय श र श य म 𝗚𝗢𝗢𝗗 𝗠𝗢𝗥𝗡𝗜𝗡𝗚 𝗧𝗥𝗔𝗗𝗘𝗥𝗦 𝗨𝗡𝗠𝗨𝗧𝗘 𝗢𝗨𝗥 𝗖...          4         2   \n",
      "315                    #stocktowatch by cnbc tv __num__          2         1   \n",
      "452   join as a premium member for more sureshot tra...          2         0   \n",
      "336                              paid group trade check          2         1   \n",
      "596   book partial profit in buy __num__ __num__ lot...          1         0   \n",
      "593   book fantastic profit in short-sell __num__ __...          1         0   \n",
      "592   on __num__ th jan __num__ booked fantastic pro...          1         0   \n",
      "590   daily nifty level for nifty traders nifty supp...          1         0   \n",
      "736   __num__ st jackpot call __num__ __num__ ce buy...          1         0   \n",
      "\n",
      "      low_msgs  avg_score  max_score  \n",
      "0          833  21.785375         90  \n",
      "1005        14  24.500000         75  \n",
      "315          4  37.142857         80  \n",
      "452          0  80.000000         90  \n",
      "336          2  52.000000         90  \n",
      "596          0  70.000000         70  \n",
      "593          0  70.000000         70  \n",
      "592          0  90.000000         90  \n",
      "590          0  90.000000         90  \n",
      "736          0  70.000000         70  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------\n",
    "# File paths\n",
    "# -----------------------\n",
    "messages_path = r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\messages_with_risk_v4.csv\"\n",
    "out_messages_clusters = r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\messages_with_clusters_v2.csv\"\n",
    "out_cluster_summary = r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\cluster_templates_v2.csv\"\n",
    "out_cluster_examples = r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\cluster_examples_v2\"\n",
    "\n",
    "# -----------------------\n",
    "# Load messages\n",
    "# -----------------------\n",
    "df = pd.read_csv(messages_path, low_memory=False)\n",
    "print(f\"Loaded messages: {len(df)}\")\n",
    "\n",
    "# Use text column\n",
    "TEXT_COL = \"text_for_model\"\n",
    "if TEXT_COL not in df.columns:\n",
    "    raise ValueError(f\"{TEXT_COL} not in dataset\")\n",
    "\n",
    "# Filter very short messages\n",
    "df = df[df[TEXT_COL].fillna(\"\").str.len() > 20].copy()\n",
    "print(f\"After removing very-short messages: {len(df)}\")\n",
    "\n",
    "# -----------------------\n",
    "# Embeddings\n",
    "# -----------------------\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "print(f\"Loading embedding model: {model_name}\")\n",
    "embedder = SentenceTransformer(model_name)\n",
    "\n",
    "embeddings = embedder.encode(df[TEXT_COL].tolist(), batch_size=64, show_progress_bar=True, convert_to_tensor=True)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "\n",
    "# -----------------------\n",
    "# Template canonicalization function\n",
    "# -----------------------\n",
    "def canonicalize(text: str) -> str:\n",
    "    \"\"\"Normalize message by stripping numbers, dates, links.\"\"\"\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" __URL__ \", text)\n",
    "    text = re.sub(r\"\\d{1,4}([.,:/-]\\d{1,4})*\", \" __NUM__ \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "df[\"canonical_text\"] = df[TEXT_COL].apply(lambda x: canonicalize(str(x)))\n",
    "\n",
    "# -----------------------\n",
    "# Clustering with similarity threshold\n",
    "# -----------------------\n",
    "clusters = []\n",
    "visited = set()\n",
    "\n",
    "cosine_threshold = 0.85  # tweakable, higher = stricter grouping\n",
    "emb_np = embeddings.cpu()\n",
    "\n",
    "for i in tqdm(range(len(df)), desc=\"Clustering\"):\n",
    "    if i in visited:\n",
    "        continue\n",
    "    sim_scores = util.cos_sim(emb_np[i], emb_np)[0]\n",
    "    cluster_idx = (sim_scores >= cosine_threshold).nonzero().flatten().tolist()\n",
    "    for j in cluster_idx:\n",
    "        visited.add(j)\n",
    "    clusters.append(cluster_idx)\n",
    "\n",
    "# Assign cluster IDs\n",
    "cluster_map = {}\n",
    "for cid, idxs in enumerate(clusters):\n",
    "    for j in idxs:\n",
    "        cluster_map[j] = cid\n",
    "df[\"cluster_id\"] = df.index.map(lambda i: cluster_map.get(i, -1))\n",
    "\n",
    "# -----------------------\n",
    "# Cluster summaries\n",
    "# -----------------------\n",
    "summaries = []\n",
    "for cid, group in df.groupby(\"cluster_id\"):\n",
    "    top_msg = group.iloc[0]\n",
    "    summaries.append({\n",
    "        \"cluster_id\": cid,\n",
    "        \"n_messages\": len(group),\n",
    "        \"example_message\": top_msg[TEXT_COL],\n",
    "        \"canonical_template\": canonicalize(top_msg[TEXT_COL]),\n",
    "        \"high_msgs\": (group[\"risk_label\"]==\"high\").sum(),\n",
    "        \"med_msgs\": (group[\"risk_label\"]==\"medium\").sum(),\n",
    "        \"low_msgs\": (group[\"risk_label\"]==\"low\").sum(),\n",
    "        \"avg_score\": group[\"heuristic_score\"].mean(),\n",
    "        \"max_score\": group[\"heuristic_score\"].max(),\n",
    "    })\n",
    "summary_df = pd.DataFrame(summaries).sort_values(\"n_messages\", ascending=False)\n",
    "\n",
    "# -----------------------\n",
    "# Save outputs\n",
    "# -----------------------\n",
    "df.to_csv(out_messages_clusters, index=False)\n",
    "summary_df.to_csv(out_cluster_summary, index=False)\n",
    "\n",
    "os.makedirs(out_cluster_examples, exist_ok=True)\n",
    "for cid, group in df.groupby(\"cluster_id\"):\n",
    "    group.head(20).to_csv(os.path.join(out_cluster_examples, f\"cluster_{cid}.csv\"), index=False)\n",
    "\n",
    "print(f\"✅ Saved message-level clusters -> {out_messages_clusters}\")\n",
    "print(f\"✅ Saved cluster summary -> {out_cluster_summary}\")\n",
    "print(f\"✅ Saved per-cluster examples -> {out_cluster_examples}\")\n",
    "\n",
    "# -----------------------\n",
    "# Show high-risk clusters\n",
    "# -----------------------\n",
    "print(\"\\nTop clusters with high-risk dominance:\")\n",
    "print(summary_df.sort_values(\"high_msgs\", ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cdfac0-c9c8-4400-89db-5fd6c7e6fb40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SEBI Project)",
   "language": "python",
   "name": "sebi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
