{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71b59a9-3acf-4238-96e9-70d85a2af9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using messages input: D:\\Darryl\\Coding\\s_p\\data\\processed\\sebi_groups_messages_preprocessed_final.csv\n",
      "Will write cleaned messages to: D:\\Darryl\\Coding\\s_p\\data\\processed\\sebi_groups_messages_preprocessed_final_v2.csv\n",
      "Loaded messages rows: 4098\n",
      "Columns detected (first 60): ['message_id', 'date', 'chat_id', 'sender_id', 'sender_username', 'sender_first_name', 'sender_last_name', 'sender_phone', 'text', 'views', 'forwards', 'reply_to_msg_id', 'media_type', 'has_hyperlink', 'group', 'text_raw', 'text_norm', 'text_clean', 'text_redacted', 'text_for_model', 'urls', 'mentions', 'hashtags', 'cashtags', 'emails', 'phones_maybe', 'emojis', 'is_system_like', 'char_count', 'word_count', 'emoji_count', 'is_promo', 'message_id_norm', 'channel_norm', 'views_norm', 'views_bucket', 'date_parsed_ist', 'hour', 'dow', 'month', 'year', 'trade_action', 'trade_strikes', 'trade_targets', 'trade_stoploss']\n",
      "Detected columns:\n",
      " - sender_username: sender_username\n",
      " - sender_first: sender_first_name\n",
      " - sender_last: sender_last_name\n",
      " - sender_phone: sender_phone\n",
      " - channel/group: chat_id\n",
      " - text: message_id\n",
      "Messages with at least one candidate name: 4098/4098 (100.00%)\n",
      "Unique candidate_name_norm_simple values: 27\n",
      "\n",
      "Top candidate names (sample):\n",
      " candidate_name_norm_simple  count\n",
      "                patelwealth    292\n",
      "           angeloneadvisory    200\n",
      "            everydayprofits    200\n",
      "          livetradingtricks    199\n",
      "               stockphoenix    197\n",
      "       vision_optiontrading    194\n",
      "                   equity99    194\n",
      "            sharesnservices    193\n",
      "            stockpro_online    192\n",
      "                 chasealpha    189\n",
      "              stockgainerss    189\n",
      "                  abhayvarn    188\n",
      "              powerofstocks    188\n",
      "               2387924796 0    184\n",
      "     darkhorseofstockmarket    183\n",
      "                   intradat    175\n",
      "                 thefinberg    168\n",
      "                 cajagdeesh    161\n",
      "              deltatrading1    137\n",
      "intradaymatchsebiregistered    123\n",
      "                    eqwires    117\n",
      "         green_traders_sebi    114\n",
      "            vgstockresearch     67\n",
      "               motilaloswal     26\n",
      "         sharekhan_official     18\n",
      "             livelongwealth      7\n",
      "             optionsgurukul      3\n",
      "\n",
      "Wrote cleaned messages file to: D:\\Darryl\\Coding\\s_p\\data\\processed\\sebi_groups_messages_preprocessed_final_v2.csv\n",
      "Wrote sample for review: D:\\Darryl\\Coding\\s_p\\data\\processed\\analysis_sample_messages_candidates.csv\n",
      "\n",
      "Examples (first 10 rows with candidate):\n",
      "  candidate_name candidate_name_source candidate_name_norm candidate_name_norm_simple                                                                                                                                                                                                                                                                                                                                                text\n",
      "AngelOneAdvisory              username    angeloneadvisory           angeloneadvisory                                          游릭 **BUY** POONAWALLA **1** shares at **435.70**.\\n\\n__Message : SL 422 TGT 457 Modify Qty/ Lot as per your discretion__\\n\\n__Created Date & Time\\n03:06 PM__\\n__23/06/25__\\n\\n__Disclaimer : __[__ www.angelone.in/research-disclaimer__](https://www.angelone.in/research-disclaimer)__ - Angel One Ltd__\n",
      "AngelOneAdvisory              username    angeloneadvisory           angeloneadvisory                                            游릭 **BUY** DMART **1** shares at **4337.00**.\\n\\n__Message : SL 4260 TGT 4460 Modify Qty/ Lot as per your discretion__\\n\\n__Created Date & Time\\n02:48 PM__\\n__23/06/25__\\n\\n__Disclaimer : __[__ www.angelone.in/research-disclaimer__](https://www.angelone.in/research-disclaimer)__ - Angel One Ltd__\n",
      "AngelOneAdvisory              username    angeloneadvisory           angeloneadvisory                                                                                                                                                                                                                                                          BOOK PROFIT IN NIFTY 24900 PE@100.2\\n\\n__Created Date & Time__\\n__02:31 PM__\\n__23/06/25__\n",
      "AngelOneAdvisory              username    angeloneadvisory           angeloneadvisory                                                                                                                                                                                                                                                                     EXIT M&M 3200CE AT 12.20\\n\\n__Created Date & Time__\\n__02:30 PM__\\n__23/06/25__\n",
      "AngelOneAdvisory              username    angeloneadvisory           angeloneadvisory                                                                                                                                                                                                                                                              BOOK PROFIT IN EICHERMOT @ 5552\\n\\n__Created Date & Time__\\n__02:22 PM__\\n__23/06/25__\n",
      "AngelOneAdvisory              username    angeloneadvisory           angeloneadvisory 游릭 **BUY** NIFTY 26 JUN 25 24900 PE **1** lots at **89.20**.\\n\\n__Expiry : 26-Jun-2025__\\n\\n__Message : SL  68.4 TGT 124 Modify Qty/ Lot as per your discretion__\\n\\n__Created Date & Time\\n02:18 PM__\\n__23/06/25__\\n\\n__Disclaimer : __[__ www.angelone.in/research-disclaimer__](https://www.angelone.in/research-disclaimer)__ - Angel One Ltd__\n",
      "AngelOneAdvisory              username    angeloneadvisory           angeloneadvisory                                 游릭 **BUY** COCHINSHIP **1** shares at **2232.50**.\\n\\n__Message : SL    2188  TGT   2305 modify Qty/ Lot as per your discretion__\\n\\n__Created Date & Time\\n01:35 PM__\\n__23/06/25__\\n\\n__Disclaimer : __[__ www.angelone.in/research-disclaimer__](https://www.angelone.in/research-disclaimer)__ - Angel One Ltd__\n",
      "AngelOneAdvisory              username    angeloneadvisory           angeloneadvisory                                                                                                                                                                                                                                                                BOOK PROFIT IN PRESTIGE @1719\\n\\n__Created Date & Time__\\n__01:32 PM__\\n__23/06/25__\n",
      "AngelOneAdvisory              username    angeloneadvisory           angeloneadvisory                                                                                                                                                                                                                                                                     Book profit in BSE @2772\\n\\n__Created Date & Time__\\n__01:31 PM__\\n__23/06/25__\n",
      "AngelOneAdvisory              username    angeloneadvisory           angeloneadvisory                                      游릭 **BUY** WIPRO **1** shares at **263.80**.\\n\\n__Message : SL   261.30   TGT   268 modify Qty/ Lot as per your discretion__\\n\\n__Created Date & Time\\n01:28 PM__\\n__23/06/25__\\n\\n__Disclaimer : __[__ www.angelone.in/research-disclaimer__](https://www.angelone.in/research-disclaimer)__ - Angel One Ltd__\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- CONFIG: change these if your files are elsewhere ----------\n",
    "# Example Windows paths you printed earlier; if running in same project, these should work.\n",
    "msgs_in_candidates = [\n",
    "    r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\sebi_groups_messages_preprocessed_final.csv\",\n",
    "    \"/mnt/data/sebi_groups_messages_preprocessed_final.csv\",  # fallback if running in Linux env\n",
    "]\n",
    "# Output path for cleaned messages (v2)\n",
    "msgs_out = r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\sebi_groups_messages_preprocessed_final_v2.csv\"\n",
    "# If you want Linux fallback:\n",
    "if not os.path.exists(os.path.dirname(msgs_out)):\n",
    "    msgs_out = \"/mnt/data/sebi_groups_messages_preprocessed_final_v2.csv\"\n",
    "\n",
    "# Try to find an existing input file from the candidates list\n",
    "msgs_in = None\n",
    "for p in msgs_in_candidates:\n",
    "    if os.path.exists(p):\n",
    "        msgs_in = p\n",
    "        break\n",
    "if msgs_in is None:\n",
    "    raise FileNotFoundError(f\"Could not find messages CSV in candidate paths. Edit msgs_in_candidates to point to your file.\")\n",
    "\n",
    "print(\"Using messages input:\", msgs_in)\n",
    "print(\"Will write cleaned messages to:\", msgs_out)\n",
    "\n",
    "# ---------- Helper normalization functions (same style as registries) ----------\n",
    "def normalize_text_for_matching(s):\n",
    "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).strip()\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    # keep Devanagari block if present, remove punctuation, collapse whitespace\n",
    "    s = re.sub(r\"[^\\w\\s\\u0900-\\u097F]\", \" \", s, flags=re.UNICODE)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.lower()\n",
    "\n",
    "def simplify_org_suffixes(s):\n",
    "    if not s:\n",
    "        return s\n",
    "    s2 = re.sub(r\"\\b(pvt|pvt\\.|ltd|ltd\\.|private|limited|llp|inc|corp|co|company|pvtltd|pvtltd)\\b\",\n",
    "                \" \", s, flags=re.I)\n",
    "    s2 = re.sub(r\"\\s+\", \" \", s2).strip()\n",
    "    return s2\n",
    "\n",
    "# ---------- Load messages CSV (be forgiving with dtype) ----------\n",
    "df = pd.read_csv(msgs_in, low_memory=False)\n",
    "\n",
    "print(\"Loaded messages rows:\", len(df))\n",
    "print(\"Columns detected (first 60):\", df.columns.tolist()[:60])\n",
    "\n",
    "# ---------- Candidate fields detection ----------\n",
    "# prefer these columns if present; fallback gracefully\n",
    "def find_col(df, keywords):\n",
    "    for col in df.columns:\n",
    "        lc = col.lower()\n",
    "        if any(k in lc for k in keywords):\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "col_sender_username = find_col(df, [\"sender_username\",\"username\",\"handle\"])\n",
    "col_sender_first = find_col(df, [\"sender_first_name\",\"first_name\",\"firstname\",\"sender_first\"])\n",
    "col_sender_last = find_col(df, [\"sender_last_name\",\"last_name\",\"lastname\",\"sender_last\"])\n",
    "col_sender_phone = find_col(df, [\"sender_phone\",\"phone\",\"mobile\",\"telephone\"])\n",
    "col_channel = find_col(df, [\"channel_norm\",\"channel\",\"group\",\"chat\",\"group_name\",\"channel_name\"])\n",
    "col_text = find_col(df, [\"text\",\"message\",\"msg\",\"body\"])\n",
    "\n",
    "print(\"Detected columns:\")\n",
    "print(\" - sender_username:\", col_sender_username)\n",
    "print(\" - sender_first:\", col_sender_first)\n",
    "print(\" - sender_last:\", col_sender_last)\n",
    "print(\" - sender_phone:\", col_sender_phone)\n",
    "print(\" - channel/group:\", col_channel)\n",
    "print(\" - text:\", col_text)\n",
    "\n",
    "# ---------- Build sender_fullname and candidate_name ------\n",
    "def safe_get(row, col):\n",
    "    if col is None or col not in row or pd.isna(row[col]):\n",
    "        return \"\"\n",
    "    return str(row[col]).strip()\n",
    "\n",
    "# Build sender_fullname\n",
    "df[\"sender_first_str\"] = df[col_sender_first].astype(str).fillna(\"\") if col_sender_first else \"\"\n",
    "df[\"sender_last_str\"]  = df[col_sender_last].astype(str).fillna(\"\") if col_sender_last else \"\"\n",
    "def combine_fullname(r):\n",
    "    a = safe_get(r, col_sender_first)\n",
    "    b = safe_get(r, col_sender_last)\n",
    "    if a and b:\n",
    "        return (a + \" \" + b).strip()\n",
    "    return a or b or \"\"\n",
    "\n",
    "df[\"sender_fullname\"] = df.apply(combine_fullname, axis=1)\n",
    "\n",
    "# Candidate fields (stringified)\n",
    "df[\"sender_username_str\"] = df[col_sender_username].astype(str).fillna(\"\") if col_sender_username else \"\"\n",
    "df[\"channel_norm_str\"] = df[col_channel].astype(str).fillna(\"\") if col_channel else \"\"\n",
    "# fallback: some files have 'group' or 'channel' exact names\n",
    "if not df[\"channel_norm_str\"].any() and \"group\" in df.columns:\n",
    "    df[\"channel_norm_str\"] = df[\"group\"].astype(str).fillna(\"\")\n",
    "\n",
    "# Choose candidate_name per row in priority order:\n",
    "# 1. username (if non-empty and not a generic 'nan'/'None')\n",
    "# 2. sender_fullname\n",
    "# 3. channel/group name\n",
    "def choose_candidate_name(row):\n",
    "    for colname, label in [(\"sender_username_str\",\"username\"), (\"sender_fullname\",\"fullname\"), (\"channel_norm_str\",\"channel\")]:\n",
    "        val = row.get(colname, \"\")\n",
    "        if val and str(val).lower() not in (\"nan\",\"none\",\"nan.0\",\"\", \"na\"):\n",
    "            return val, label\n",
    "    return \"\", \"none\"\n",
    "\n",
    "candidates = df.apply(lambda r: choose_candidate_name(r), axis=1)\n",
    "df[\"candidate_name\"], df[\"candidate_name_source\"] = zip(*candidates)\n",
    "\n",
    "# Normalize candidate name variants\n",
    "df[\"candidate_name_norm\"] = df[\"candidate_name\"].apply(normalize_text_for_matching)\n",
    "df[\"candidate_name_norm_simple\"] = df[\"candidate_name_norm\"].apply(simplify_org_suffixes)\n",
    "\n",
    "# ---------- Summary stats & sample output ----------\n",
    "n_candidates = df[\"candidate_name\"].astype(bool).sum()\n",
    "pct_with_candidate = n_candidates / len(df) * 100.0\n",
    "unique_candidates = df[\"candidate_name_norm_simple\"].nunique()\n",
    "\n",
    "print(f\"Messages with at least one candidate name: {n_candidates}/{len(df)} ({pct_with_candidate:.2f}%)\")\n",
    "print(\"Unique candidate_name_norm_simple values:\", unique_candidates)\n",
    "\n",
    "# Show top candidate names (frequency)\n",
    "top_candidates = df[\"candidate_name_norm_simple\"].value_counts().head(30).reset_index()\n",
    "top_candidates.columns = [\"candidate_name_norm_simple\",\"count\"]\n",
    "print(\"\\nTop candidate names (sample):\")\n",
    "print(top_candidates.to_string(index=False))\n",
    "\n",
    "# Write cleaned messages file\n",
    "df.to_csv(msgs_out, index=False)\n",
    "print(\"\\nWrote cleaned messages file to:\", msgs_out)\n",
    "\n",
    "# Save a small sample for quick review (first 500 rows)\n",
    "sample_path = os.path.join(os.path.dirname(msgs_out), \"analysis_sample_messages_candidates.csv\")\n",
    "df[[\"candidate_name\",\"candidate_name_source\",\"candidate_name_norm\",\"candidate_name_norm_simple\",\"text\"]].head(500).to_csv(sample_path, index=False)\n",
    "print(\"Wrote sample for review:\", sample_path)\n",
    "\n",
    "# Show a few example rows where candidate_name exists\n",
    "examples = df[df[\"candidate_name\"].astype(bool)].head(10)[[\"candidate_name\",\"candidate_name_source\",\"candidate_name_norm\",\"candidate_name_norm_simple\",\"text\"]]\n",
    "print(\"\\nExamples (first 10 rows with candidate):\")\n",
    "print(examples.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ee598-81ac-4fb8-ac22-c8c34a4d47ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SEBI Project)",
   "language": "python",
   "name": "sebi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
