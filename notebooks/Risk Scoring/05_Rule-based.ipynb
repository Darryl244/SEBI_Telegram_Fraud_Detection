{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fee9c2c-92ba-4d87-b439-5d1dda2201c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input messages: D:\\Darryl\\Coding\\s_p\\data\\processed\\messages_with_verification.csv\n",
      "Output messages: D:\\Darryl\\Coding\\s_p\\data\\processed\\messages_with_risk_v1.csv\n",
      "Loaded rows: 4098\n",
      "Using text column: text_for_model\n",
      "Analyzing messages (rule-based)...\n",
      " processed 500 / 4098\n",
      " processed 1000 / 4098\n",
      " processed 1500 / 4098\n",
      " processed 2000 / 4098\n",
      " processed 2500 / 4098\n",
      " processed 3000 / 4098\n",
      " processed 3500 / 4098\n",
      " processed 4000 / 4098\n",
      "Saved messages with risk: D:\\Darryl\\Coding\\s_p\\data\\processed\\messages_with_risk_v1.csv\n",
      "Saved sample: D:\\Darryl\\Coding\\s_p\\data\\processed\\analysis_sample_messages_risk.csv\n",
      "\n",
      "Risk distribution:\n",
      "risk_label\n",
      "medium    4550\n",
      "low        219\n",
      "high        23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top messages flagged high (sample):\n",
      " message_id  candidate_name candidate_name_norm_simple risk_label  heuristic_score                                                                                      explain\n",
      "     5606.0   PowerOfStocks              powerofstocks       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n",
      "     5664.0   PowerOfStocks              powerofstocks       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n",
      "     5673.0   PowerOfStocks              powerofstocks       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n",
      "     5687.0   PowerOfStocks              powerofstocks       high             79.0                Keywords matched: \\bwhatsapp\\b, rs  | Marked promo | Phone-like token present\n",
      "     5693.0   PowerOfStocks              powerofstocks       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n",
      "     5736.0   PowerOfStocks              powerofstocks       high             87.0 Keywords matched: \\bwhatsapp\\b, \\bhot stock\\b, rs  | Marked promo | Phone-like token present\n",
      "     5509.0 SharesNservices            sharesnservices       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n",
      "     5568.0 SharesNservices            sharesnservices       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n",
      "     5606.0 SharesNservices            sharesnservices       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n",
      "     5650.0 SharesNservices            sharesnservices       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n",
      "     5664.0 SharesNservices            sharesnservices       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n",
      "     5673.0 SharesNservices            sharesnservices       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n",
      "     5682.0 SharesNservices            sharesnservices       high             87.0   Keywords matched: \\bwhatsapp\\b, \\bbuy now\\b, rs  | Marked promo | Phone-like token present\n",
      "     5687.0 SharesNservices            sharesnservices       high             79.0                Keywords matched: \\bwhatsapp\\b, rs  | Marked promo | Phone-like token present\n",
      "     5693.0 SharesNservices            sharesnservices       high             71.0                     Keywords matched: \\bwhatsapp\\b | Marked promo | Phone-like token present\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------- CONFIG: file paths ----------\n",
    "msgs_in = r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\messages_with_verification.csv\"\n",
    "msgs_out = r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\messages_with_risk_v1.csv\"\n",
    "sample_out = os.path.join(os.path.dirname(msgs_out), \"analysis_sample_messages_risk.csv\")\n",
    "\n",
    "# fallback if path not present (e.g., Linux environment)\n",
    "if not os.path.exists(os.path.dirname(msgs_out)):\n",
    "    msgs_in = \"/mnt/data/messages_with_verification.csv\" if os.path.exists(\"/mnt/data/messages_with_verification.csv\") else \"/mnt/data/sebi_groups_messages_preprocessed_final_v2.csv\"\n",
    "    msgs_out = \"/mnt/data/messages_with_risk_v1.csv\"\n",
    "    sample_out = \"/mnt/data/analysis_sample_messages_risk.csv\"\n",
    "\n",
    "print(\"Input messages:\", msgs_in)\n",
    "print(\"Output messages:\", msgs_out)\n",
    "\n",
    "# ---------- Load messages ----------\n",
    "df = pd.read_csv(msgs_in, low_memory=False)\n",
    "print(\"Loaded rows:\", len(df))\n",
    "\n",
    "# choose a text column to analyze; prefer 'text_for_model' then 'text_clean' then 'text'\n",
    "for col_try in [\"text_for_model\",\"text_clean\",\"text\",\"text_norm\",\"text_raw\"]:\n",
    "    if col_try in df.columns:\n",
    "        text_col = col_try\n",
    "        break\n",
    "print(\"Using text column:\", text_col)\n",
    "\n",
    "# ---------- Scam keyword lists (English + Hindi/Hinglish) ----------\n",
    "# Keep this list conservative; expand when needed.\n",
    "SCAM_KEYWORDS = [\n",
    "    # typical scam phrases/promises\n",
    "    r\"\\b100% returns\\b\", r\"\\bguaranteed returns\\b\", r\"\\bguaranteed\\b\", r\"\\bno risk\\b\", r\"\\brisk[- ]free\\b\",\n",
    "    r\"\\bget rich\\b\", r\"\\bmake money fast\\b\", r\"\\bmake quick profits\\b\", r\"\\bdouble your money\\b\",\n",
    "    r\"\\btrust me\\b\", r\"\\bDM for calls\\b\", r\"\\bDM for tips\\b\", r\"\\bcontact on whatsapp\\b\", r\"\\bwhatsapp\\b\",\n",
    "    r\"\\bjoin my group\\b\", r\"\\binside info\\b\", r\"\\binsider tips\\b\", r\"\\bsecret strategy\\b\",\n",
    "    r\"\\bbuy now\\b\", r\"\\bsell now\\b\", r\"\\bhot stock\\b\", r\"\\bcan't miss\\b\", r\"\\bcan't lose\\b\",\n",
    "    # payment / collection patterns (UPI strings are probably redacted, but check words)\n",
    "    r\"\\bupi\\b\", r\"\\bpaytm\\b\", r\"\\bphonepe\\b\", r\"\\bgpay\\b\", r\"\\bgoogle pay\\b\", r\"\\bcollect\\b\", r\"\\baccount number\\b\",\n",
    "    # urgency and FOMO\n",
    "    r\"\\blast chance\\b\", r\"\\blimited spots\\b\", r\"\\blimited time\\b\", r\"\\bact now\\b\", r\"\\bcall now\\b\",\n",
    "    # disclaimers mimicry (fake regulatory claims)\n",
    "    r\"\\bSEBI registered\\b\", r\"\\bSEBI reg\\b\", r\"\\bSEBI registered advisor\\b\", r\"\\bregistered with sebi\\b\",\n",
    "    # Hindi/Hinglish (simple tokens)\n",
    "    r\"लाख\", r\"कमाओ\", r\"सुनहरा मौका\", r\"100% लाभ\", r\"बिना जोखिम\", r\"निश्चित लाभ\", r\"मुनाफ़ा\", r\"सुन\", r\"कमाई\",\n",
    "    r\"paise\", r\"₹\", r\"rs\\.\", r\"rs \"\n",
    "]\n",
    "\n",
    "SCAM_KEYWORDS = [re.compile(k, flags=re.IGNORECASE) for k in SCAM_KEYWORDS]\n",
    "\n",
    "# ---------- Heuristic scoring weights ----------\n",
    "WEIGHTS = {\n",
    "    \"keyword\": 40,        # presence of scam keywords (max)\n",
    "    \"promo\": 10,          # is_promo flag\n",
    "    \"unverified\": 25,     # candidate not found in SEBI (big bump)\n",
    "    \"trade_signal\": 15,   # contains explicit trade_action (calls to trade)\n",
    "    \"phone_url\": 10       # presence of phone/url (likely redacted; for completeness)\n",
    "}\n",
    "# ensure total possible may exceed 100 — we'll clip to 100 at end.\n",
    "\n",
    "# helper regexes\n",
    "url_re = re.compile(r'https?://\\S+|www\\.\\S+', re.IGNORECASE)\n",
    "phone_re = re.compile(r'(\\+91[\\-\\s]?[6-9]\\d{9}|\\b[6-9]\\d{9}\\b|\\+?\\d{7,15})')\n",
    "\n",
    "# normalization helper\n",
    "def text_safe(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    return str(s)\n",
    "\n",
    "# ---------- detection logic per message ----------\n",
    "def analyze_message(row):\n",
    "    text = text_safe(row.get(text_col, \"\"))\n",
    "    res = {\n",
    "        \"matched_keywords\": [],\n",
    "        \"heuristic_score\": 0.0,\n",
    "        \"reasons\": []\n",
    "    }\n",
    "\n",
    "    # 1) keyword matches\n",
    "    keyword_hits = []\n",
    "    for pat in SCAM_KEYWORDS:\n",
    "        if pat.search(text):\n",
    "            keyword_hits.append(pat.pattern)\n",
    "    if keyword_hits:\n",
    "        # weight scales with number of unique keywords found\n",
    "        kw_points = min(len(keyword_hits) / 5.0 * WEIGHTS[\"keyword\"], WEIGHTS[\"keyword\"])  # 5 or more keywords => full points\n",
    "        res[\"heuristic_score\"] += kw_points\n",
    "        res[\"matched_keywords\"] = keyword_hits\n",
    "        res[\"reasons\"].append(f\"Keywords matched: {', '.join(keyword_hits[:4])}\")\n",
    "\n",
    "    # 2) is_promo feature\n",
    "    if str(row.get(\"is_promo\", \"\")).strip().lower() in (\"1\",\"true\",\"yes\",\"y\",\"t\"):\n",
    "        res[\"heuristic_score\"] += WEIGHTS[\"promo\"]\n",
    "        res[\"reasons\"].append(\"Marked promo\")\n",
    "\n",
    "    # 3) phone / url presence (if not redacted)\n",
    "    if url_re.search(text):\n",
    "        res[\"heuristic_score\"] += WEIGHTS[\"phone_url\"]\n",
    "        res[\"reasons\"].append(\"Contains URL\")\n",
    "    # phones_maybe column may exist but text phones likely redacted\n",
    "    if \"phones_maybe\" in row and not pd.isna(row.get(\"phones_maybe\")) and str(row.get(\"phones_maybe\")).strip():\n",
    "        res[\"heuristic_score\"] += WEIGHTS[\"phone_url\"]\n",
    "        res[\"reasons\"].append(\"Phone-like token present\")\n",
    "\n",
    "    # 4) trade signal (calls to buy/sell with targets) — use trade_action or trade_* fields if present\n",
    "    trade_action = str(row.get(\"trade_action\", \"\")).strip().lower()\n",
    "    if trade_action in (\"buy\",\"sell\",\"call\",\"put\",\"long\",\"short\"):\n",
    "        res[\"heuristic_score\"] += WEIGHTS[\"trade_signal\"]\n",
    "        res[\"reasons\"].append(f\"Explicit trade_action: {trade_action}\")\n",
    "    else:\n",
    "        # fallback: look for \"buy\" \"sell\" tokens in text\n",
    "        if re.search(r'\\bbuy\\b|\\bsell\\b|\\bexit\\b|\\bbook profit\\b|\\bsl\\b|\\btgt\\b', text, flags=re.IGNORECASE):\n",
    "            res[\"heuristic_score\"] += WEIGHTS[\"trade_signal\"]/2.0\n",
    "            res[\"reasons\"].append(\"Trade-like tokens in text\")\n",
    "\n",
    "    # 5) SEBI verification status bump\n",
    "    status = str(row.get(\"status\", \"\")).strip().lower()\n",
    "    if status == \"unverified\":\n",
    "        res[\"heuristic_score\"] += WEIGHTS[\"unverified\"]\n",
    "        res[\"reasons\"].append(\"Advisor not SEBI-verified\")\n",
    "\n",
    "    # 6) short message length or emoji-heavy promo (suspicious)\n",
    "    if \"emoji_count\" in row and not pd.isna(row.get(\"emoji_count\")) and int(float(row.get(\"emoji_count\") or 0)) > 3:\n",
    "        res[\"heuristic_score\"] += 3\n",
    "        res[\"reasons\"].append(\"Many emojis\")\n",
    "\n",
    "    # 7) clamp and finalize\n",
    "    score = float(res[\"heuristic_score\"])\n",
    "    score = max(0.0, min(100.0, score))\n",
    "    res[\"heuristic_score\"] = round(score, 2)\n",
    "\n",
    "    # risk label\n",
    "    if score >= 70:\n",
    "        label = \"high\"\n",
    "    elif score >= 35:\n",
    "        label = \"medium\"\n",
    "    else:\n",
    "        label = \"low\"\n",
    "    res[\"risk_label\"] = label\n",
    "\n",
    "    # short human reasons (limit to 3 bullets)\n",
    "    if res[\"reasons\"]:\n",
    "        res[\"explain\"] = \" | \".join(res[\"reasons\"][:3])\n",
    "    else:\n",
    "        res[\"explain\"] = \"No strong heuristics matched\"\n",
    "\n",
    "    return res\n",
    "\n",
    "# ---------- Run analysis on all messages ----------\n",
    "print(\"Analyzing messages (rule-based)...\")\n",
    "out_rows = []\n",
    "for i, row in df.iterrows():\n",
    "    a = analyze_message(row)\n",
    "    out_rows.append({\n",
    "        \"message_id\": row.get(\"message_id\", None),\n",
    "        \"heuristic_score\": a[\"heuristic_score\"],\n",
    "        \"risk_label\": a[\"risk_label\"],\n",
    "        \"matched_keywords\": \";\".join(a[\"matched_keywords\"]) if a[\"matched_keywords\"] else \"\",\n",
    "        \"explain\": a[\"explain\"]\n",
    "    })\n",
    "    if (i+1) % 500 == 0:\n",
    "        print(f\" processed {i+1} / {len(df)}\")\n",
    "\n",
    "df_out = pd.DataFrame(out_rows).set_index(\"message_id\")\n",
    "# merge back into original df (on message_id)\n",
    "if \"message_id\" in df.columns:\n",
    "    df = df.set_index(\"message_id\").merge(df_out, left_index=True, right_index=True, how=\"left\").reset_index()\n",
    "else:\n",
    "    df = pd.concat([df, df_out.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# ---------- save outputs ----------\n",
    "df.to_csv(msgs_out, index=False)\n",
    "df.head(200).to_csv(sample_out, index=False)\n",
    "print(\"Saved messages with risk:\", msgs_out)\n",
    "print(\"Saved sample:\", sample_out)\n",
    "\n",
    "# quick summary\n",
    "print(\"\\nRisk distribution:\")\n",
    "print(df['risk_label'].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nTop messages flagged high (sample):\")\n",
    "print(df[df['risk_label']=='high'][['message_id','candidate_name','candidate_name_norm_simple','risk_label','heuristic_score','explain']].head(15).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467640f-caf7-4b39-b15e-3a1b38bc827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# -----------------------\n",
    "# File paths\n",
    "# -----------------------\n",
    "messages_path = r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\messages_with_verification.csv\"\n",
    "output_messages_path = r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\messages_with_risk_v4.csv\"\n",
    "output_sample_path = r\"D:\\Darryl\\Coding\\s_p\\data\\processed\\analysis_sample_messages_risk_v4.csv\"\n",
    "\n",
    "# -----------------------\n",
    "# Load data\n",
    "# -----------------------\n",
    "df = pd.read_csv(messages_path, low_memory=False)\n",
    "print(f\"Loaded rows: {len(df)}\")\n",
    "\n",
    "# -----------------------\n",
    "# Keyword patterns (English + Hindi/Hinglish)\n",
    "# -----------------------\n",
    "\n",
    "# Strong promo/pump signals\n",
    "promo_keywords = [\n",
    "    # English\n",
    "    r\"\\bjoin now\\b\", r\"\\bsubscribe\\b\", r\"\\bwhatsapp\\b\", r\"\\btelegram\\b\",\n",
    "    r\"\\boffer\\b\", r\"\\bprofit\\b\", r\"\\bjackpot\\b\", r\"\\bbuy now\\b\", \n",
    "    r\"\\bsure shot\\b\", r\"\\bhot stock\\b\", r\"\\bcall now\\b\", r\"\\bmultibagger\\b\",\n",
    "    r\"\\btarget hits\\b\", r\"\\bguarantee\\b\",\n",
    "\n",
    "    # Hindi/Hinglish\n",
    "    r\"\\bbhai log\\b\", r\"\\bsure shot call\\b\", r\"\\bpaise double\\b\",\n",
    "    r\"\\blakhpati banoge\\b\", r\"\\bkarodpati\\b\", r\"\\bkal ka tezi stock\\b\",\n",
    "    r\"\\b100% return\\b\", r\"\\bchhupaa hua gem\\b\", r\"\\bsuvarna avsar\\b\",\n",
    "    r\"\\bsuvarn avsar\\b\", r\"\\btip\\b\", r\"\\btelegram join karo\\b\",\n",
    "    r\"\\bsignal\\b\", r\"\\bguranteed\\b\", r\"\\bcaller id\\b\"\n",
    "]\n",
    "\n",
    "# Trading action tokens\n",
    "trade_keywords = [\n",
    "    r\"\\bbuy\\b\", r\"\\bsell\\b\", r\"\\btarget\\b\", r\"\\bstoploss\\b\", \n",
    "    r\"\\bintraday\\b\", r\"\\bshort term\\b\", r\"\\blong term\\b\",\n",
    "    r\"\\bhit tgt\\b\", r\"\\btgt\\b\", r\"\\bsafe call\\b\"\n",
    "]\n",
    "\n",
    "# Money-related\n",
    "money_patterns = [\n",
    "    r\"\\brs\\b\", r\"\\b₹\\b\", r\"\\b\\d{3,}\\b\", r\"\\b1\\.5 lakh\\b\", r\"\\blakh\\b\", r\"\\bcr\\b\"\n",
    "]\n",
    "\n",
    "promo_re = re.compile(\"|\".join(promo_keywords), re.IGNORECASE)\n",
    "trade_re = re.compile(\"|\".join(trade_keywords), re.IGNORECASE)\n",
    "money_re = re.compile(\"|\".join(money_patterns), re.IGNORECASE)\n",
    "\n",
    "# -----------------------\n",
    "# Scoring function\n",
    "# -----------------------\n",
    "def score_message(text, verified_status, confidence):\n",
    "    if not isinstance(text, str):\n",
    "        return 0, \"No text\", \"low\"\n",
    "\n",
    "    score = 0\n",
    "    reasons = []\n",
    "\n",
    "    # Promo signals (strong weight)\n",
    "    if promo_re.search(text):\n",
    "        score += 40\n",
    "        reasons.append(\"Promo keywords detected\")\n",
    "\n",
    "    # Trade signals\n",
    "    trade_matches = len(trade_re.findall(text))\n",
    "    if trade_matches > 0:\n",
    "        score += 10 * min(trade_matches, 3)\n",
    "        reasons.append(f\"Trade tokens detected ({trade_matches})\")\n",
    "\n",
    "    # Money references\n",
    "    if money_re.search(text):\n",
    "        score += 20\n",
    "        reasons.append(\"Money-related token\")\n",
    "\n",
    "    # Phone/WhatsApp-like numbers\n",
    "    if re.search(r\"\\+?\\d{8,}\", text):\n",
    "        score += 25\n",
    "        reasons.append(\"Phone-like token present\")\n",
    "\n",
    "    # Links\n",
    "    if \"http\" in text or \"www\" in text:\n",
    "        score += 15\n",
    "        reasons.append(\"Link detected\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Confidence-based adjustment\n",
    "    # -----------------------\n",
    "    if verified_status == \"unverified\":\n",
    "        if confidence >= 90:\n",
    "            score += 20\n",
    "            reasons.append(\"Unverified but very close to registry name (⚠️ suspicious)\")\n",
    "        elif confidence >= 70:\n",
    "            score += 10\n",
    "            reasons.append(\"Unverified but somewhat close to registry name\")\n",
    "\n",
    "    # Bound score\n",
    "    score = min(score, 100)\n",
    "\n",
    "    # Map to risk labels\n",
    "    if score >= 70:\n",
    "        label = \"high\"\n",
    "    elif score >= 40:\n",
    "        label = \"medium\"\n",
    "    else:\n",
    "        label = \"low\"\n",
    "\n",
    "    return score, \" | \".join(reasons), label\n",
    "\n",
    "# -----------------------\n",
    "# Apply to messages\n",
    "# -----------------------\n",
    "risk_scores, explanations, labels = [], [], []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    sc, exp, label = score_message(\n",
    "        row.get(\"text_for_model\", \"\"),\n",
    "        row.get(\"status\", \"unverified\"),\n",
    "        row.get(\"confidence\", 0)\n",
    "    )\n",
    "    risk_scores.append(sc)\n",
    "    explanations.append(exp)\n",
    "    labels.append(label)\n",
    "\n",
    "df[\"heuristic_score\"] = risk_scores\n",
    "df[\"explain\"] = explanations\n",
    "df[\"risk_label\"] = labels\n",
    "\n",
    "# -----------------------\n",
    "# Save results\n",
    "# -----------------------\n",
    "df.to_csv(output_messages_path, index=False)\n",
    "df.sample(200).to_csv(output_sample_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved messages with risk: {output_messages_path}\")\n",
    "print(f\"✅ Saved sample: {output_sample_path}\")\n",
    "\n",
    "# -----------------------\n",
    "# Summary\n",
    "# -----------------------\n",
    "print(\"\\nRisk distribution:\")\n",
    "print(df[\"risk_label\"].value_counts())\n",
    "\n",
    "print(\"\\nTop messages flagged high (sample):\")\n",
    "print(df[df[\"risk_label\"] == \"high\"].head(15)[\n",
    "    [\"message_id\",\"candidate_name\",\"candidate_name_norm_simple\",\"risk_label\",\"heuristic_score\",\"explain\"]\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SEBI Project)",
   "language": "python",
   "name": "sebi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
